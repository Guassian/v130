---
title: " Scalable Gaussian Process Variational Autoencoders "
abstract: " Conventional variational autoencoders fail in modeling correlations between
  data points due to their use of factorized priors. Amortized Gaussian process inference
  through GP-VAEs has led to significant improvements in this regard, but is still
  inhibited by the intrinsic complexity of exact GP inference. We improve the scalability
  of these methods through principled sparse inference approaches. We propose a new
  scalable GP-VAE model that outperforms existing approaches in terms of runtime and
  memory footprint, is easy to implement, and allows for joint end-to-end optimization
  of all components. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jazbec21a
month: 0
tex_title: " Scalable Gaussian Process Variational Autoencoders "
firstpage: 3511
lastpage: 3519
page: 3511-3519
order: 3511
cycles: false
bibtex_author: Jazbec, Metod and Ashman, Matt and Fortuin, Vincent and Pearce, Michael
  and Mandt, Stephan and R{\"a}tsch, Gunnar
author:
- given: Metod
  family: Jazbec
- given: Matt
  family: Ashman
- given: Vincent
  family: Fortuin
- given: Michael
  family: Pearce
- given: Stephan
  family: Mandt
- given: Gunnar
  family: RÃ¤tsch
date: 2021-03-18
address:
container-title: Proceedings of The 24th International Conference on Artificial Intelligence
  and Statistics
volume: '130'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 3
  - 18
pdf: http://proceedings.mlr.press/v130/jazbec21a/jazbec21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v130/jazbec21a/jazbec21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
