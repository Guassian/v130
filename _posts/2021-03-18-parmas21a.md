---
title: " A unified view of likelihood ratio and reparameterization gradients "
abstract: " Reparameterization (RP) and likelihood ratio (LR) gradient estimators
  are used to estimate gradients of expectations throughout machine learning and reinforcement
  learning; however, they are usually explained as simple mathematical tricks, with
  no insight into their nature. We use a first principles approach to explain that
  LR and RP are alternative methods of keeping track of the movement of probability
  mass, and the two are connected via the divergence theorem. Moreover, we show that
  the space of all possible estimators combining LR and RP can be completely parameterized
  by a flow field u(x) and importance sampling distribution q(x). We prove that there
  cannot exist a single-sample estimator of this type outside our characterized space,
  thus, clarifying where we should be searching for better Monte Carlo gradient estimators. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: parmas21a
month: 0
tex_title: " A unified view of likelihood ratio and reparameterization gradients "
firstpage: 4078
lastpage: 4086
page: 4078-4086
order: 4078
cycles: false
bibtex_author: Parmas, Paavo and Sugiyama, Masashi
author:
- given: Paavo
  family: Parmas
- given: Masashi
  family: Sugiyama
date: 2021-03-18
address: 
container-title: Proceedings of The 24th International Conference on Artificial Intelligence
  and Statistics
volume: '130'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 3
  - 18
pdf: http://proceedings.mlr.press/v130/parmas21a/parmas21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v130/parmas21a/parmas21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
