---
title: " Mirror Descent View for Neural Network Quantization "
abstract: " Quantizing large Neural Networks (NN) while maintaining the performance
  is highly desirable for resource-limited devices due to reduced memory and time
  complexity. It is usually formulated as a constrained optimization problem and optimized
  via a modified version of gradient descent. In this work, by interpreting the continuous
  parameters (unconstrained) as the dual of the quantized ones, we introduce a Mirror
  Descent (MD) framework for NN quantization. Specifically, we provide conditions
  on the projections (i.e., mapping from continuous to quantized ones) which would
  enable us to derive valid mirror maps and in turn the respective MD updates. Furthermore,
  we present a numerically stable implementation of MD that requires storing an additional
  set of auxiliary variables (unconstrained), and show that it is strikingly analogous
  to the Straight Through Estimator (STE) based method which is typically viewed as
  a “trick” to avoid vanishing gradients issue. Our experiments on CIFAR-10/100, TinyImageNet,
  and ImageNet classification datasets with VGG-16, ResNet-18, and MobileNetV2 architectures
  show that our MD variants yield state-of-the-art performance. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ajanthan21a
month: 0
tex_title: " Mirror Descent View for Neural Network Quantization "
firstpage: 2809
lastpage: 2817
page: 2809-2817
order: 2809
cycles: false
bibtex_author: Ajanthan, Thalaiyasingam and Gupta, Kartik and Torr, Philip and HARTLEY,
  RICHARD and Dokania, Puneet
author:
- given: Thalaiyasingam
  family: Ajanthan
- given: Kartik
  family: Gupta
- given: Philip
  family: Torr
- given: RICHARD
  family: HARTLEY
- given: Puneet
  family: Dokania
date: 2021-03-18
address:
container-title: Proceedings of The 24th International Conference on Artificial Intelligence
  and Statistics
volume: '130'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 3
  - 18
pdf: http://proceedings.mlr.press/v130/ajanthan21a/ajanthan21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v130/ajanthan21a/ajanthan21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
