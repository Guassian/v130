---
title: " Taming heavy-tailed features by shrinkage "
abstract: " In this work, we focus on a variant of the generalized linear model (GLM)
  called corrupted GLM (CGLM) with heavy-tailed features and responses. To robustify
  the statistical inference on this model, we propose to apply L4-norm shrinkage to
  the feature vectors in the low-dimensional regime and apply elementwise shrinkage
  to them in the high-dimensional regime. Under bounded fourth moment assumptions,
  we show that the maximum likelihood estimator (MLE) based on the shrunk data enjoys
  nearly the minimax optimal rate with an exponential deviation bound. Our simulations
  demonstrate that the proposed feature shrinkage significantly enhances the statistical
  performance in linear regression and logistic regression on heavy-tailed data. Finally,
  we apply our shrinkage principle to guard against mislabeling and image noise in
  the human-written digit recognition problem. We add an L4-norm shrinkage layer to
  the original neural net and reduce the testing misclassification rate by more than
  30% relatively in the presence of mislabeling and image noise. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhu21c
month: 0
tex_title: " Taming heavy-tailed features by shrinkage "
firstpage: 3268
lastpage: 3276
page: 3268-3276
order: 3268
cycles: false
bibtex_author: Zhu, Ziwei and Zhou, Wenjing
author:
- given: Ziwei
  family: Zhu
- given: Wenjing
  family: Zhou
date: 2021-03-18
address: 
container-title: Proceedings of The 24th International Conference on Artificial Intelligence
  and Statistics
volume: '130'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 3
  - 18
pdf: http://proceedings.mlr.press/v130/zhu21c/zhu21c.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v130/zhu21c/zhu21c-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
