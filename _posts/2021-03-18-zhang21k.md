---
title: " Efficient Designs Of SLOPE Penalty Sequences In Finite Dimension "
abstract: " In linear regression, SLOPE is a new convex analysis method that generalizes
  the Lasso via the sorted $\\ell_1$ penalty: larger fitted coefficients are penalized
  more heavily. This magnitude-dependent regularization requires an input of penalty
  sequence $\\blam$, instead of a scalar penalty as in the Lasso case, thus making
  the design extremely expensive in computation. In this paper, we propose two efficient
  algorithms to design the possibly high-dimensional SLOPE penalty, in order to minimize
  the mean squared error. For Gaussian data matrices, we propose a first order Projected
  Gradient Descent (PGD) under the Approximate Message Passing regime. For general
  data matrices, we present a zero-th order Coordinate Descent (CD) to design a sub-class
  of SLOPE, referred to as the $k$-level SLOPE. Our CD allows a useful trade-off between
  the accuracy and the computation speed. We demonstrate the performance of SLOPE
  with our designs via extensive experiments on synthetic data and real-world datasets. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang21k
month: 0
tex_title: " Efficient Designs Of SLOPE Penalty Sequences In Finite Dimension "
firstpage: 3277
lastpage: 3285
page: 3277-3285
order: 3277
cycles: false
bibtex_author: Zhang, Yiliang and Bu, Zhiqi
author:
- given: Yiliang
  family: Zhang
- given: Zhiqi
  family: Bu
date: 2021-03-18
address: 
container-title: Proceedings of The 24th International Conference on Artificial Intelligence
  and Statistics
volume: '130'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 3
  - 18
pdf: http://proceedings.mlr.press/v130/zhang21k/zhang21k.pdf
extras:
- label: Supplementary ZIP
  link: http://proceedings.mlr.press/v130/zhang21k/zhang21k-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
