---
title: " Q-learning with Logarithmic Regret "
abstract: " This paper presents the first non-asymptotic result showing a model-free
  algorithm can achieve logarithmic cumulative regret for episodic tabular reinforcement
  learning if there exists a strictly positive sub-optimality gap. We prove that the
  optimistic Q-learning studied in [Jin et al. 2018] enjoys a ${\\mathcal{O}}\\!\\left(\\frac{SA\\cdot
  \\mathrm{poly}\\left(H\\right)}{\\Delta_{\\min}}\\log\\left(SAT\\right)\\right)$
  cumulative regret bound where $S$ is the number of states, $A$ is the number of
  actions, $H$ is the planning horizon, $T$ is the total number of steps, and $\\Delta_{\\min}$
  is the minimum sub-optimality gap of the optimal Q-function. This bound matches
  the information theoretical lower bound in terms of $S,A,T$ up to a $\\log\\left(SA\\right)$
  factor. We further extend our analysis to the discounted setting and obtain a similar
  logarithmic cumulative regret bound. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yang21b
month: 0
tex_title: " Q-learning with Logarithmic Regret "
firstpage: 1576
lastpage: 1584
page: 1576-1584
order: 1576
cycles: false
bibtex_author: Yang, Kunhe and Yang, Lin and Du, Simon
author:
- given: Kunhe
  family: Yang
- given: Lin
  family: Yang
- given: Simon
  family: Du
date: 2021-03-18
address: 
container-title: Proceedings of The 24th International Conference on Artificial Intelligence
  and Statistics
volume: '130'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 3
  - 18
pdf: http://proceedings.mlr.press/v130/yang21b/yang21b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v130/yang21b/yang21b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
