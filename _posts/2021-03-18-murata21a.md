---
title: " Gradient Descent in RKHS with Importance Labeling "
abstract: " Labeling cost is often expensive and is a fundamental limitation of supervised
  learning. In this paper, we study importance labeling problem, in which we are given
  many unlabeled data and select a limited number of data to be labeled from the unlabeled
  data, and then a learning algorithm is executed on the selected one. We propose
  a new importance labeling scheme that can effectively select an informative subset
  of unlabeled data in least squares regression in Reproducing Kernel Hilbert Spaces
  (RKHS). We analyze the generalization error of gradient descent combined with our
  labeling scheme and show that the proposed algorithm achieves the optimal rate of
  convergence in much wider settings and especially gives much better generalization
  ability in a small noise setting than the usual uniform sampling scheme. Numerical
  experiments verify our theoretical findings. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: murata21a
month: 0
tex_title: " Gradient Descent in RKHS with Importance Labeling "
firstpage: 1981
lastpage: 1989
page: 1981-1989
order: 1981
cycles: false
bibtex_author: Murata, Tomoya and Suzuki, Taiji
author:
- given: Tomoya
  family: Murata
- given: Taiji
  family: Suzuki
date: 2021-03-18
address: 
container-title: Proceedings of The 24th International Conference on Artificial Intelligence
  and Statistics
volume: '130'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 3
  - 18
pdf: http://proceedings.mlr.press/v130/murata21a/murata21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v130/murata21a/murata21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
