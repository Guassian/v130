---
title: " Anderson acceleration of coordinate descent "
abstract: " Acceleration of first order methods is mainly obtained via inertia Ã  la
  Nesterov, or via nonlinear extrapolation. The latter has known a recent surge of
  interest, with successful applications to gradient and proximal gradient techniques.
  On multiple Machine Learning problems, coordinate descent achieves performance significantly
  superior to full-gradient methods. Speeding up coordinate descent in practice is
  not easy: inertially accelerated versions of coordinate descent are theoretically
  accelerated, but might not always lead to practical speed-ups. We propose an accelerated
  version of coordinate descent using extrapolation, showing considerable speed up
  in practice, compared to inertial accelerated coordinate descent and extrapolated
  (proximal) gradient descent. Experiments on least squares, Lasso, elastic net and
  logistic regression validate the approach. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: bertrand21a
month: 0
tex_title: " Anderson acceleration of coordinate descent "
firstpage: 1288
lastpage: 1296
page: 1288-1296
order: 1288
cycles: false
bibtex_author: Bertrand, Quentin and Massias, Mathurin
author:
- given: Quentin
  family: Bertrand
- given: Mathurin
  family: Massias
date: 2021-03-18
address:
container-title: Proceedings of The 24th International Conference on Artificial Intelligence
  and Statistics
volume: '130'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 3
  - 18
pdf: http://proceedings.mlr.press/v130/bertrand21a/bertrand21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v130/bertrand21a/bertrand21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
