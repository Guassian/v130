---
title: " Fork or Fail: Cycle-Consistent Training with Many-to-One Mappings "
abstract: " Cycle-consistent training is widely used for jointly learning a forward
  and inverse mapping between two domains of interest without the cumbersome requirement
  of collecting matched pairs within each domain. In this regard, the implicit assumption
  is that there exists (at least approximately) a ground-truth bijection such that
  a given input from either domain can be accurately reconstructed from successive
  application of the respective mappings. But in many applications no such bijection
  can be expected to exist and large reconstruction errors can compromise the success
  of cycle-consistent training. As one important instance of this limitation, we consider
  practically-relevant situations where there exists a many-to-one or surjective mapping
  between domains. To address this regime, we develop a conditional variational autoencoder
  (CVAE) approach that can be viewed as converting surjective mappings to implicit
  bijections whereby reconstruction errors in both directions can be minimized, and
  as a natural byproduct, realistic output diversity can be obtained in the one-to-many
  direction. As theoretical motivation, we analyze a simplified scenario whereby minima
  of the proposed CVAE-based energy function align with the recovery of ground-truth
  surjective mappings. On the empirical side, we consider a synthetic image dataset
  with known ground-truth, as well as a real-world application involving natural language
  generation from knowledge graphs and vice versa, a prototypical surjective case.
  For the latter, our CVAE pipeline can capture such many-to-one mappings during cycle
  training while promoting textural diversity for graph-to-text tasks. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: guo21b
month: 0
tex_title: " Fork or Fail: Cycle-Consistent Training with Many-to-One Mappings "
firstpage: 1828
lastpage: 1836
page: 1828-1836
order: 1828
cycles: false
bibtex_author: Guo, Qipeng and Jin, Zhijing and Wang, Ziyu and Qiu, Xipeng and Zhang,
  Weinan and Zhu, Jun and Zhang, Zheng and David, Wipf
author:
- given: Qipeng
  family: Guo
- given: Zhijing
  family: Jin
- given: Ziyu
  family: Wang
- given: Xipeng
  family: Qiu
- given: Weinan
  family: Zhang
- given: Jun
  family: Zhu
- given: Zheng
  family: Zhang
- given: Wipf
  family: David
date: 2021-03-18
address: 
container-title: Proceedings of The 24th International Conference on Artificial Intelligence
  and Statistics
volume: '130'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 3
  - 18
pdf: http://proceedings.mlr.press/v130/guo21b/guo21b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v130/guo21b/guo21b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
