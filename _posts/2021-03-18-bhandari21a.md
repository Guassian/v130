---
title: " On the Linear Convergence of Policy Gradient Methods for Finite MDPs "
abstract: " We revisit the finite time analysis of policy gradient methods in the
  one of the simplest settings: finite state and action MDPs with a policy class consisting
  of all stochastic policies and with exact gradient evaluations. There has been some
  recent work viewing this setting as an instance of smooth non-linear optimization
  problems, to show sub-linear convergence rates with small step-sizes. Here, we take
  a completely different perspective based on illuminating connections with policy
  iteration, to show how many variants of policy gradient algorithms succeed with
  large step-sizes and attain a linear rate of convergence. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: bhandari21a
month: 0
tex_title: " On the Linear Convergence of Policy Gradient Methods for Finite MDPs "
firstpage: 2386
lastpage: 2394
page: 2386-2394
order: 2386
cycles: false
bibtex_author: Bhandari, Jalaj and Russo, Daniel
author:
- given: Jalaj
  family: Bhandari
- given: Daniel
  family: Russo
date: 2021-03-18
address: 
container-title: Proceedings of The 24th International Conference on Artificial Intelligence
  and Statistics
volume: '130'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 3
  - 18
pdf: http://proceedings.mlr.press/v130/bhandari21a/bhandari21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v130/bhandari21a/bhandari21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
