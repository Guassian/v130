---
title: " One-Round Communication Efficient Distributed M-Estimation "
abstract: " Communication cost and local computation complexity are two main bottlenecks
  of the distributed statistical learning. In this paper, we consider the distributed
  M-estimation problem in both regular and sparse case and propose a novel one-round
  communication efficient algorithm. For regular distributed M-estimator, the asymptotic
  normality is provided to conduct statistical inference. For sparse distributed M-estimator,
  we only require solving a quadratic Lasso problem in the master machine using the
  same local information as the regular distributed M-estimator. Consequently, the
  computation complexity of the local machine is sufficiently reduced compared with
  the existing debiased sparse estimator. Under mild conditions, the theoretical results
  guarantee that our proposed distributed estimators achieve (near)optimal statistical
  convergence rate. The effectiveness of our proposed algorithm is verified through
  experiments across different M-estimation problems using both synthetic and real
  benchmark datasets. "
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: bao21a
month: 0
tex_title: " One-Round Communication Efficient Distributed M-Estimation "
firstpage: 46
lastpage: 54
page: 46-54
order: 46
cycles: false
bibtex_author: Bao, Yajie and Xiong, Weijia
author:
- given: Yajie
  family: Bao
- given: Weijia
  family: Xiong
date: 2021-03-18
address: 
container-title: Proceedings of The 24th International Conference on Artificial Intelligence
  and Statistics
volume: '130'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 3
  - 18
pdf: http://proceedings.mlr.press/v130/bao21a/bao21a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v130/bao21a/bao21a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
